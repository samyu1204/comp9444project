{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13c77fe9",
   "metadata": {},
   "source": [
    "# COMP9444 Group Project\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e76861f",
   "metadata": {},
   "source": [
    "## 1. Introduction, Motivation, and/or Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186b2962",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "Our project aims to leverage computer vision neural network to improve object detection of images during both daytime and nighttime environments. The ability to accurately detect and recognize objects in varying lighting condition has become crucial for the functionalities of many modern day applications; some examples would be autonomous vehicles, surveillance and security systems.\n",
    "\n",
    "Consider the two images below. It is imperative that everything in left image is very easy to identify, and when contrasted to the image on the right it really highlights just how much harder it is to identify objects with low luminosity.\n",
    "<div style=\"margin-top: 20px; margin-bottom: 20px;\">\n",
    "<img src=\"https://www.exposit.com/wp-content/webp-express/webp-images/doc-root/wp-content/uploads/2021/04/Illumination_conditions_as_a_challenge_of_comp.width-800.jpg.webp\" width=\"500\"/>\n",
    "</div>\n",
    "\n",
    "### Motivation\n",
    "Modern day computer vision neural networks often fail to perform well in nighttime object detection (inaccurate detection of objects in low luminosity environments). Nighttime environment factors like shadow, limited luminosity, and visibility makes it challenging for the network to classify objects. With this problem, it can hinder the effectiveness and safety of pre-existing computer vision applications like surveillance, which requires all day monitoring.\n",
    "\n",
    "Researchers have made advancements in enhancing accuracy for low-light detection. An example is the REDI low-light enhancement algorithm, which effectively filters noise in low-light conditions and performs detection on the resulting image.\n",
    "<div style=\"margin-top: 20px; margin-bottom: 20px;\">\n",
    "<img src=\"./images/lowlight.png\" />\n",
    "</div>\n",
    "\n",
    "Here (a) through to (d) are stages of REDI algorithm filtering. However, there are many downsides to this algorithm like loss of details, over-correction, and high computational cost. This would pose a challenge as it would add extra complexity and computational stress on existing models.\n",
    "\n",
    "Solving day/night object detection will definitely bring significant enhancements in the real world, and some key areas of improvements are autonomous driving, surveillance and security systems. This is not only an exciting technical challenge for researchers, but also has the potential to open up new possibilities for neural network computer vision advancements.\n",
    "\n",
    "### Problem Statements\n",
    "Key challenges that requires to be address by our models are:\n",
    "1. The model requires to handle varying levels of brightness within the image.\n",
    "2. Removing noise from nighttime image, as image taken at night might have more noise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09dfb5a6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2e923798",
   "metadata": {},
   "source": [
    "## 2. Exploration Analysis or Data or RL Tasks\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f399faf",
   "metadata": {},
   "source": [
    "## 3. Models and/or Methods\n",
    "\n",
    "### 2DPASS \n",
    "Link to paper: https://arxiv.org/pdf/2210.04208.pdf\n",
    "\n",
    "#### Model Introduction\n",
    "This model is an Assisted Semantic Segmentation method that boosts the representation learning on point clouds. A notable advantage of this model is that \n",
    "Advantages of this model is that it does not require strict pair data alignments between the camera and LiDAR data. \n",
    "\n",
    "The 2DPASS method leverages an auxiliary model fusion and multi-scale fusion to single knowledge distillation (MSFSKD) to acquire richer semantic and structural information from the multi-modal data. This is a significant improvement over baseline models where models only use point cloud.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0254fdf1",
   "metadata": {},
   "source": [
    "## 4. Results\n",
    "\n",
    "### 2DPASS Results\n",
    "\n",
    "#### 2DPASS Trained on Mini-Dataset\n",
    "<div style=\"margin-top: 20px; margin-bottom: 20px;\">\n",
    "<img src=\"./images/mini.png\" />\n",
    "</div>\n",
    "\n",
    "#### 2DPASS Pretrained Model\n",
    "<div style=\"margin-top: 20px; margin-bottom: 20px;\">\n",
    "<img src=\"./images/pretrained.png\" />\n",
    "</div>\n",
    "\n",
    "#### Model Results\n",
    "| Model                | mIoU | Accuracy |\n",
    "|----------------------|------|----------|\n",
    "| 2DPASS (Mini-dataset)| 36%  | 56%      |\n",
    "| 2DPASS (Pretrained)  | 81%  | 63%      |\n",
    "\n",
    "Major improvements in accuracy and mIoU are both significant for the pretrained model which was initially trained on the full dataset. Note, that this result is worse than the one displayed in the paper as their model was trained with additional validation set and using instance-level augmentation.\n",
    "\n",
    "#### Epoch Training Steps\n",
    "NOTE: X-axis is number of epoch.\n",
    "##### mIoU vs Epoch \n",
    "<div style=\"margin-top: 20px; margin-bottom: 20px;\">\n",
    "<img src=\"./images/miou_r.png\" width=\"700px\" />\n",
    "</div>\n",
    "##### Best mIoU vs Epoch \n",
    "<div style=\"margin-top: 20px; margin-bottom: 20px;\">\n",
    "<img src=\"./images/miou.png\" width=\"700px\" />\n",
    "</div>\n",
    "\n",
    "From the mIoU curves and best mIoU curve(smoothened out), we see that around 8000 epoch there are no significant improves in the mIoU value, emphasizing that further training after 8000 epoch does not improve the model, and could lead to overfitting existing data.\n",
    "\n",
    "##### Accuracy vs Epoch \n",
    "<div style=\"margin-top: 20px; margin-bottom: 20px;\">\n",
    "<img src=\"./images/accuracy.png\" width=\"700px\" />\n",
    "</div>\n",
    "The accuracy during the training of the model behaves similarly to the mIoU curve as optimum accuracy is reached around 8000 epoche"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6d9427",
   "metadata": {},
   "source": [
    "## 5. Discussion\n",
    "### 2DPASS Discussion\n",
    "#### System Performance:\n",
    "System Specifications:\n",
    "We have trained the 2DPASS model on a Nvidia 4060 laptop graphics card with 16 gigabytes of RAM. \n",
    "\n",
    "#### Dataset:\n",
    "For the interest of time we have used the mini-training dataset of nuscenes which is around 6 gigabytes compared to the 80 gigabytes full dataset.\n",
    "\n",
    "#### Training Specifications\n",
    "Training batch size had to be limited to a size of 1 as any batch sizes larger than this would cause insufficient memory errors.\n",
    "Training parameters have been pre-tuned by the developers as:\n",
    "- Learning Rate: 0.24\n",
    "- Optimizer: SGD\n",
    "- Momentum: 0.9\n",
    "- Weight Decay: 1.0e-4\n",
    "\t\n",
    "#### Model Architecture\n",
    "This model significantly improves upon simple image computer vision neural networks, as 2DPASS introduces lidar detection combined with the use of image. This more accurately detects the existence and classification of the object even in low luminosity environments.\n",
    "\n",
    "#### Training Time\n",
    "The training process of our model on the mini-dataset took approximately 5 hours, which is due to our computerâ€™s limited memory as it was only able to manage a batch training size of one. Also, due to the limited variety in the mini-dataset, we observed that the val/mIoU failed to show improvements over the last 50 records, which shows that a lot of the computation towards the end of training did not achieve any notable performance improvements.\n",
    "<div style=\"margin-top: 20px; margin-bottom: 20px;\">\n",
    "<img src=\"./images/train_time.png\" />\n",
    "</div>\n",
    "\n",
    "#### Challenges and Solutions\n",
    "Originally running the model on the whole 80 gigabytes data requires too much computational power and time, so we resorted to using the mini-training set instead, which was much faster to train.\n",
    "\n",
    "Training on a much smaller dataset could potentially introduce overfitting of data and lead to inaccurate results, in this case we have used their pre-trained model to compare results before drawing conclusions.\n",
    "<div style=\"margin-top: 20px; margin-bottom: 20px;\">\n",
    "<img src=\"./images/overfit.png\" />\n",
    "</div>\n",
    "The above is the result from testing the model trained with the mini-dataset, and here we can clearly see a case of overfitting where all vehicle like objects are recognised as cars explaining the high accuracy in car predictions and basically 0% accuracy in all other vehicles detections.\n",
    "\n",
    "Our main challenges occurred within our limited ability to modify the model, as the training time even on a much smaller dataset took up to five hours. To tackle this problem, we have introduced early-stopping of the training, where if we do not see noticeable improvements on the mIoU(mean intersection over Union) value over five epochs of training we will manually exit the training. However, finding a sweet spot for the improvement was difficult and is hard to optimise. Moreover, as training is also dependent on the distribution of the dataset, it is uncertain how much the model will learn from processing different data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907ef7c0",
   "metadata": {},
   "source": [
    "### References (To be cleaned up later)\n",
    "https://www.exposit.com/blog/computer-vision-object-detection-challenges-faced/\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
